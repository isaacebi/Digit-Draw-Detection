{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import torch\n",
    "import base64\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURR_PATH = os.getcwd()\n",
    "PROJECT_PATH = os.path.dirname(CURR_PATH)\n",
    "DATA_PATH = os.path.join(PROJECT_PATH, 'data')\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, 'train')\n",
    "TEST_PATH = os.path.join(DATA_PATH, 'test')\n",
    "RES_PATH = os.path.join(PROJECT_PATH, 'res')\n",
    "MODELS_PATH = os.path.join(PROJECT_PATH, 'models')\n",
    "RLHF_PATH = os.path.join(DATA_PATH, 'RLHF.db')\n",
    "\n",
    "# Check if GPU is available, and set the device accordingly\n",
    "device =  torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check folder is exist, if not then create folder\n",
    "def check_path(folderPaths:list):\n",
    "    for folderPath in folderPaths:\n",
    "        if not os.path.exists(folderPath):\n",
    "            os.makedirs(folderPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check path\n",
    "check_path([\n",
    "    TRAIN_PATH, TEST_PATH,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download training & test data and put in DATA_PATH\n",
    "mnist_trainset = datasets.MNIST(\n",
    "    root=TRAIN_PATH, \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "mnist_testset = datasets.MNIST(\n",
    "    root=TEST_PATH, \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Prep\n",
    "train_dataloader = DataLoader(\n",
    "    mnist_trainset, \n",
    "    batch_size=20, \n",
    "    shuffle=True, \n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    mnist_testset, \n",
    "    batch_size=20, \n",
    "    shuffle=False, \n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # First Convolutional Layer\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),\n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        \n",
    "        # Second Convolutional Layer\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        \n",
    "        # Fully Connected Layer for Classification\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the first convolutional layer\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        # Forward pass through the second convolutional layer\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        # Flatten the output for the fully connected layer\n",
    "        x = x.view(x.size(0), -1)  # flattening the layer      \n",
    "        \n",
    "        # Forward pass through the fully connected layer for classification\n",
    "        output = self.out(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(model_output, target):\n",
    "    # get the prediction\n",
    "    predictions = torch.max(model_output, 1)[1].data.squeeze()\n",
    "    \n",
    "    # get the accuracy\n",
    "    accuracy = (predictions == target).sum().item()/float(target.size(0))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, num_epoch, loss_function, optimizer, train_dataloader):\n",
    "    \"\"\"\n",
    "    Function to train the CNN model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The DL model to be trained.\n",
    "    - num_epoch: Iteration to be train\n",
    "    - loss_function: The loss function used for training.\n",
    "    - optimizer: The optimization algorithm used for updating model parameters.\n",
    "    - train_dataloader: DataLoader providing training data.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    # model training \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        \n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        i = 0\n",
    "        for i, (images, labels) in enumerate(train_dataloader):\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(images)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = loss_function(output, labels)\n",
    "            \n",
    "            # Releasing the cache\n",
    "            optimizer.zero_grad() \n",
    "            \n",
    "            # Backward Pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update model parameter\n",
    "            optimizer.step()\n",
    "\n",
    "            # accummulate the loss and accuracy for each epoch\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_accuracy += calculate_accuracy(output, labels)\n",
    "\n",
    "        print(f\"Epoch: {epoch} - Loss: {epoch_loss} - Accuracy: {epoch_accuracy/(i+1)}\")\n",
    "\n",
    "\n",
    "def test_model(model, test_dataloader):\n",
    "    \"\"\"\n",
    "    Function to test the CNN model on a given dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained DL model to be tested.\n",
    "    - test_dataloader: DataLoader providing test data.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    accuracy = 0\n",
    "    i = 0\n",
    "    for i, (images, labels) in enumerate(test_dataloader):\n",
    "\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(images)\n",
    "\n",
    "        # Accumulate accuracy\n",
    "        accuracy += calculate_accuracy(output, labels)\n",
    "\n",
    "    # Print test accuracy\n",
    "    print(f\"Test Accuracy: {accuracy / (i + 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the CNN model and move it to the specified device (GPU or CPU)\n",
    "cnn_model = CNN().to(device)\n",
    "\n",
    "# Define the loss function (cross-entropy) - for classification problem\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer (Adam) for updating the model parameters during training\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Loss: 317.98804757976177 - Accuracy: 0.9680333333333294\n",
      "Epoch: 1 - Loss: 174.56941176936016 - Accuracy: 0.9830333333333268\n",
      "Epoch: 2 - Loss: 153.98018257774373 - Accuracy: 0.9848999999999947\n",
      "Epoch: 3 - Loss: 140.38584096728073 - Accuracy: 0.9868166666666593\n",
      "Epoch: 4 - Loss: 121.21884261796752 - Accuracy: 0.9883833333333288\n",
      "Epoch: 5 - Loss: 122.27417995003461 - Accuracy: 0.9884166666666605\n",
      "Epoch: 6 - Loss: 114.99268381551488 - Accuracy: 0.9895999999999945\n",
      "Epoch: 7 - Loss: 115.35596555538473 - Accuracy: 0.9905666666666617\n",
      "Epoch: 8 - Loss: 108.80548466048455 - Accuracy: 0.9907333333333285\n",
      "Epoch: 9 - Loss: 114.09904385531509 - Accuracy: 0.990866666666663\n"
     ]
    }
   ],
   "source": [
    "# model training \n",
    "cnn_model.train()\n",
    "\n",
    "for epoch in range(10):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    i = 0\n",
    "    for i, (images, labels) in enumerate(train_dataloader):\n",
    "\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        output = cnn_model(images)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = loss_function(output, labels)\n",
    "        \n",
    "        # Releasing the cache\n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        # Backward Pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameter\n",
    "        optimizer.step()\n",
    "\n",
    "        # accummulate the loss and accuracy for each epoch\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_accuracy += calculate_accuracy(output, labels)\n",
    "\n",
    "    print(f\"Epoch: {epoch} - Loss: {epoch_loss} - Accuracy: {epoch_accuracy/(i+1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9842999999999986\n"
     ]
    }
   ],
   "source": [
    "test_model(cnn_model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ResNet-based image classifier\n",
    "class ResNetImageClassifier(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained=True):\n",
    "        super(ResNetImageClassifier, self).__init__()\n",
    "\n",
    "        self.gray_img = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=3,\n",
    "            kernel_size=7\n",
    "        )\n",
    "        \n",
    "        # Load the pre-trained ResNet model\n",
    "        weights = ResNet18_Weights.DEFAULT\n",
    "        self.resnet = resnet18(weights=weights)\n",
    "        \n",
    "        # Modify the last layer to match the number of classes\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input through the ResNet model\n",
    "        x = self.gray_img(x)\n",
    "        x = self.resnet(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = ResNetImageClassifier(num_classes=len(mnist_trainset.classes)).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9922999999999992\n"
     ]
    }
   ],
   "source": [
    "test_model(model, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
